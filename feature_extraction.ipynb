{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE EXTRACTION (for the example file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped input shape for model: (19740, 3, 300)\n",
      "Data shape ready for SSL-Wearables ResNet model: torch.Size([19740, 3, 300])\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load HDF5 file\n",
    "hdf5_filename = \"data/preprocessed/preprocessed_data.h5\"\n",
    "segment_duration = 600  # 10 minutes (600s), matches 30Hz\n",
    "time_steps = segment_duration * 30  # 30Hz sampling rate\n",
    "\n",
    "def load_hdf5_data(file_path):\n",
    "    \"\"\"Loads HDF5 data and converts it into (batch_size, 3, T) format.\"\"\"\n",
    "    all_segments = []\n",
    "    \n",
    "    with h5py.File(file_path, \"r\") as hf:\n",
    "        for night in hf.keys():  # Iterate through nights\n",
    "            x = hf[night][\"x\"][:]\n",
    "            y = hf[night][\"y\"][:]\n",
    "            z = hf[night][\"z\"][:]\n",
    "            \n",
    "            # Stack to form (3, T) format\n",
    "            data = np.stack([x, y, z], axis=0)  # Shape: (3, total_timesteps)\n",
    "            \n",
    "            # Split into 10-minute segments\n",
    "            for i in range(0, data.shape[1] - time_steps, time_steps):\n",
    "                segment = data[:, i:i+time_steps]  # Shape: (3, T)\n",
    "                all_segments.append(segment)\n",
    "    \n",
    "    all_segments = np.array(all_segments)  # Convert list to numpy array\n",
    "    return all_segments\n",
    "\n",
    "# Load and preprocess data\n",
    "data_segments = load_hdf5_data(hdf5_filename)\n",
    "\n",
    "# Convert to 10-second windows before passing through model\n",
    "window_size = 300  # 10 sec Ã— 30Hz\n",
    "num_windows = 18000 // window_size  # Each 10-minute segment contains 60 windows\n",
    "\n",
    "# Reshape data to break 10-minute segments into 10-second segments\n",
    "reshaped_data = data_segments.reshape(-1, 3, window_size)  # Shape: (total_windows, 3, 300)\n",
    "\n",
    "print(f\"Reshaped input shape for model: {reshaped_data.shape}\")  # Should be (num_samples * 60, 3, 300)\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "data_tensor = torch.tensor(reshaped_data, dtype=torch.float32)\n",
    "\n",
    "print(f\"Data shape ready for SSL-Wearables ResNet model: {data_tensor.shape}\")  # Should be (num_samples * 60, 3, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/sara/.cache/torch/hub/OxWearables_ssl-wearables_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 Weights loaded\n",
      "Input shape: torch.Size([19740, 3, 300])\n",
      "Extracted feature shape: (19740, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model from SSL-Wearables\n",
    "repo = \"OxWearables/ssl-wearables\"\n",
    "resnet_model = torch.hub.load(repo, \"harnet10\", class_num=5, pretrained=True)  # Load model\n",
    "resnet_model = resnet_model.feature_extractor  # Keep only the feature extractor part\n",
    "\n",
    "# Debugging\n",
    "print(f\"Input shape: {data_tensor.shape}\")  # Should be (batch_size, 3, 300)\n",
    "\n",
    "# Extract features in batches\n",
    "extracted_features = []\n",
    "resnet_model.eval()  # Set to evaluation mode (no gradients needed)\n",
    "\n",
    "with torch.no_grad():  # Disable gradient tracking\n",
    "    for batch in data_tensor:\n",
    "        batch = batch.unsqueeze(0).to(\"cpu\")  # Add batch dimension\n",
    "        batch_features = resnet_model(batch).squeeze(-1)  # Extract features\n",
    "        extracted_features.append(batch_features.numpy())  # Convert to NumPy\n",
    "\n",
    "# Convert extracted features into a NumPy array\n",
    "extracted_features = np.vstack(extracted_features)  # Shape: (total_samples, feature_dim)\n",
    "\n",
    "print(f\"Extracted feature shape: {extracted_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to 'data/features/extracted_features.npy'\n"
     ]
    }
   ],
   "source": [
    "# Save features for later classification\n",
    "np.save(\"data/features/extracted_features.npy\", extracted_features)\n",
    "\n",
    "print(f\"Features saved to 'data/features/extracted_features.npy'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Feature Extraction)",
   "language": "python",
   "name": "env_feature_extraction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
